# 回归 Regression

**回归**定义了输入与输出的关系，输入即现有知识，而输出则为预测。

回归方法是一种对数值型连续随机变量进行预测和建模的监督学习算法。使用案例一般包括房价预测、股票走势或测试成绩等连续变化的案例。

回归任务的特点是标注的数据集具有数值型的目标变量。也就是说，每一个观察样本都有一个数值型的标注真值以监督算法。回归的目的在于得到一个最优的拟合线。


### 回归的步骤

一个预测问题在回归模型下的解决步骤为：

1）积累知识： 将储备的知识称之为训练集 Training Set。  

2）学习：学习如何预测，得到输入与输出的关系。在学习阶段，应当有合适的指导方针，学习算法 （ Learning Algorithm ）。

3）预测：学习完成后，当接受了新的数据（输入）后，通过学习阶段获得的对应关系来预测输出。

### 回归方法

1）线性回归（正则化）

线性回归是处理回归任务最常用的算法之一。该算法的形式十分简单，它期望使用一个超平面拟合数据集（只有两个变量的时候就是一条直线）。  

2）回归树（集成方法）

回归树（决策树的一种）通过将数据集重复分割为不同的分支而实现分层学习，分割的标准是最大化每一次分离的信息增益。这种分支结构让回归树很自然地学习到非线性关系。



### 回归与其他问题的联系

- 输入变量与输出变量均为连续变量的预测问题是回归问题；

- 输出变量为有限个离散变量的预测问题成为分类问题；

- 输入变量与输出变量均为变量序列的预测问题成为标注问题。


### 参考来源：

【1】  https://yoyoyohamapi.gitbooks.io/mit-ml/content/线性回归/articles/回归问题.html

【2】  https://www.jiqizhixin.com/articles/2017-05-20-3