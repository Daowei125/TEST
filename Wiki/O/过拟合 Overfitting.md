# 过拟合 Overfitting

**过拟合** 是机器学习中的一种现象。指把样本中一些并不需要拿来作为分类的属性学习了的情况，此时学习的决策树模型并不是最优的模型，而且会会导致泛化性能下降。


### 过拟合造成的影响

在统计学和机器学习中，过拟合一般在描述统计学模型随机误差或噪音时用到。它通常发生在模型过于复杂的情况下，如参数过多等。过拟合会使得模型的预测性能变弱，并且增加数据的波动性。

### 避免过拟合可采取的措施

导致过拟合的因素有很多种，通常是由于学习能力过于强大。所以如果一味追求提高对训练数据的预测能力，所选择模型的复杂度往往比真模型更高，就会出现过拟合。


为了避免过拟合，有必要使用一些额外的技术，如交叉验证、正则化、 early stopping 、贝斯信息量准则、赤池信息量准则或 model comparison ，以指出何时会有更多训练而没有导致更好的一般化。

### 过拟合与欠拟合

与过拟合相对的是“欠拟合”（ underfitting ），指对训练样本不够，导致对样本的一般性质尚未学好。


##### 相关词：欠拟合

### 参考来源：

【1】  https://en.wikipedia.org/wiki/Overfitting 

【2】  https://blog.csdn.net/Dream_angel_Z/article/details/48898817